{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import scipy as sci\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_similarity_graph(X: np.ndarray, sigma=1, epsilon=0):\n",
    "    \"\"\" X (n x d): coordinates of the n data points in R^d.\n",
    "        sigma (float): width of the kernel\n",
    "        epsilon (float): threshold\n",
    "        Return:\n",
    "        adjacency (n x n ndarray): adjacency matrix of the graph.\n",
    "    \"\"\"  \n",
    "    distance=squareform(pdist(X, 'euclidean'))\n",
    "    #print(np.mean(distance))\n",
    "    weights=np.exp(-distance**2/(2*sigma*sigma))\n",
    "    np.fill_diagonal(weights,0)\n",
    "    #plt.hist(weights.reshape(weights.shape[0]**2 ,1),bins=100)\n",
    "    #plt.title(\"distance treshold\")\n",
    "    #plt.show()\n",
    "    adjacency=weights\n",
    "    adjacency[adjacency<epsilon]=0\n",
    "    return adjacency\n",
    "\"\"\"\"\"\n",
    "def compute_laplacian(adjacency: np.ndarray, normalize: bool):\n",
    "    Degrees=np.diag(np.sum(adjacency,1))\n",
    "    #print(  (np.sum(adjacency,1) == 0).any()   )\n",
    "    if normalize==False:\n",
    "        L=Degrees-adjacency\n",
    "    if normalize==True:\n",
    "        D_norm=np.diag(np.sum(adjacency,1)**(-1/2))\n",
    "        L=D_norm@(Degrees-adjacency)@D_norm\n",
    "    return L\n",
    "\"\"\"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "def compute_laplacian(adjacency: np.ndarray, normalize: bool):\n",
    "    \"\"\" Return:\n",
    "        L (n x n ndarray): combinatorial or symmetric normalized Laplacian.\n",
    "    \"\"\"\n",
    "    D = np.diag(np.sum(adjacency, 1)) # Degree matrix\n",
    "    combinatorial = D - adjacency\n",
    "    if normalize:\n",
    "        D_norm = np.diag(np.clip(np.sum(adjacency, 1), 1, None)**(-1/2))\n",
    "        return D_norm @ combinatorial @ D_norm\n",
    "    else:\n",
    "        return combinatorial\n",
    "\n",
    "    \n",
    "\n",
    "def spectral_decomposition(laplacian: np.ndarray):\n",
    "    lamb, U=sci.linalg.eigh(laplacian)\n",
    "    sorted_idx = np.argsort(lamb)\n",
    "    lamb = lamb[sorted_idx]\n",
    "    U=U[:,sorted_idx]\n",
    "    return lamb,U\n",
    "\n",
    "\n",
    "def GFT(signal, U):\n",
    "    # Your code here\n",
    "    print(len(signal))\n",
    "    return U.T @ signal\n",
    "\n",
    "def iGFT(fourier_coefficients, U):\n",
    "    # Your code here\n",
    "    return U @ fourier_coefficients\n",
    "def ideal_graph_filter(x, spectral_response, U):\n",
    "    \"\"\"Return a filtered signal.\"\"\"\n",
    "    # Your code here\n",
    "    # spectral_response is in the fourier domain\n",
    "    # x is in the graph domain\n",
    "    # need to converge x to the fourier domain \n",
    "    # finally convert all back to the graph domain\n",
    "    return iGFT(GFT(x,U) * spectral_response, U)\n",
    "\n",
    "def pred_iteration(A,iters, x, n, filtered_x_lp):\n",
    "    f1_scores =[]\n",
    "    for i in iters:\n",
    "        test_idx = np.random.choice(np.arange(len(x)),n,replace = False)\n",
    "        # masking some winner\n",
    "        x[test_idx]=0\n",
    "        #prepare ground truth\n",
    "        truth = (df_merged_total[\"winner\"][test_idx]).values\n",
    "\n",
    "        pred = []\n",
    "        for i in test_idx:\n",
    "            l = np.where(A[i] !=0)[0]  # searching neigbhours\n",
    "            tmp = 0\n",
    "            for j in l:\n",
    "                \n",
    "                tmp += filtered_x_lp[j]\n",
    "            pred.append(tmp/len(l))   # compute mean\n",
    "        # thresholding\n",
    "        pred_thres = np.array(pred)\n",
    "        pred_thres [pred_thres >0 ] = 1\n",
    "        pred_thres [pred_thres <0 ] = -1\n",
    "\n",
    "        # ground truth\n",
    "        truth = (df_merged_total[\"winner\"][test_idx]).values\n",
    "\n",
    "        #right_pred = []\n",
    "        f1_scores.append(sm.f1_score(truth,pred_thres))\n",
    "        #for i in range(len(pred_thres)):\n",
    "        #    if(pred_thres[i] == truth[i]):\n",
    "        #        right_pred.append(i)\n",
    "        #accuracy.append( len(right_pred)/len(test_idx))\n",
    "        \n",
    "    mean = np.mean(f1_scores)\n",
    "    var = np.std(f1_scores)\n",
    "    print(\"The mean is \",mean)\n",
    "    print(\"The variance is \",var)\n",
    "    return mean,var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_migrations = pd.read_csv(\"./NTDS_Data/countyinflow1516.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_migrations = pd.read_csv(\"./NTDS_Data/countyinflow1516.csv\" )\n",
    "\n",
    "# keep only summury information of each county\n",
    "df_migrations = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration\")]\n",
    "\n",
    "# create the combined fips county number \n",
    "df_migrations['statefips_str'] = df_migrations['y2_statefips'].apply(lambda x : str(x).zfill(2))\n",
    "df_migrations['countyfips_str'] = df_migrations['y2_countyfips'].apply(lambda x : str(x).zfill(3))\n",
    "df_migrations['combined_fips'] = df_migrations['statefips_str'].apply(lambda x: x.lstrip('0')) + df_migrations['countyfips_str']\n",
    "\n",
    "# drop useless information \n",
    "df_migrations = df_migrations.drop(columns=[\"y2_statefips\", \"y2_countyfips\", \"y1_statefips\", \"y1_countyfips\", \"y1_state\", \"statefips_str\", \"countyfips_str\"])\n",
    "\n",
    "# seperate each possible migration into three dataframe \n",
    "df_migration_total = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US and Foreign\")]\n",
    "df_migrations['y1_countyname'] = df_migrations['y1_countyname'].apply(lambda x : x if x.find(\"County Total Migration-US and Foreign\") == -1 else \"County Total Migration Both\")\n",
    "df_migration_us = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US\")]\n",
    "df_migration_for = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-Foreign\")]\n",
    "\n",
    "# drop the name of the column \n",
    "df_migration_total = df_migration_total.drop(columns=[\"y1_countyname\"])\n",
    "df_migration_us = df_migration_us.drop(columns=[\"y1_countyname\"])\n",
    "df_migration_for = df_migration_for.drop(columns=[\"y1_countyname\"])\n",
    "\n",
    "# remove nodes where data is undefined undefined data by zero\n",
    "df_migration_total = df_migration_total[df_migration_total['n1'] != -1]\n",
    "df_migration_us = df_migration_us[df_migration_us['n1'] != -1]\n",
    "df_migration_for = df_migration_for[df_migration_for['n1'] != -1]\n",
    "\n",
    "# convert combined fips to int64\n",
    "df_migration_total['combined_fips'] = df_migration_total['combined_fips'].astype('int64')\n",
    "df_migration_us['combined_fips'] = df_migration_us['combined_fips'].astype('int64')\n",
    "df_migration_for['combined_fips'] = df_migration_for['combined_fips'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presidential_result = pd.read_csv(\"./NTDS_Data/2016_US_County_Level_Presidential_Results.csv\" )\n",
    "df_presidential_result = df_presidential_result.drop(columns=[\"Unnamed: 0\",\"votes_dem\", \"votes_gop\", \"total_votes\", \"diff\", \"per_point_diff\", \"state_abbr\", \"county_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataset and drop useless column, add a new column winner \n",
    "df_merged_total = pd.merge(df_migration_total, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_us = pd.merge(df_migration_us, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_for = pd.merge(df_migration_for, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_total['difference'] = df_merged_total['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_us['difference'] = df_merged_us['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_for['difference'] = df_merged_for['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_total['winner'] = df_merged_total['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_us['winner'] = df_merged_us['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_for['winner'] = df_merged_for['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_total = df_merged_total.drop(columns=['difference'])\n",
    "df_merged_us = df_merged_us.drop(columns=['difference'])\n",
    "df_merged_for = df_merged_for.drop(columns=['difference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division by zero in normalized lapacien computation\n",
    "\n",
    "- some nodes do not have any connection in the graph => create new adjacency matrix A by deleting these nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = df_merged_total.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_total = df_merged_total.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_total['agi'] = (X_total['agi'] - X_total['agi'].mean()) / X_total['agi'].std()\n",
    "X_total['prop_ret/exempt'] = X_total['n1'] / X_total['n2']\n",
    "X_total = X_total.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_total = epsilon_similarity_graph(X_total, sigma=0.5284353963018223*0.1, epsilon=0.2)\n",
    "#plt.spy(adjacency_RGB_total)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly choose some points for prediction use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2958    1\n",
      "2959   -1\n",
      "2960    1\n",
      "2961    1\n",
      "2962    1\n",
      "Name: winner, Length: 2963, dtype: int64\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prepare A and x(signal)\n",
    "A = adjacency_RGB_total.copy()\n",
    "rows_to_be_deleted = np.where(np.sum(adjacency_RGB_total,1) == 0)\n",
    "A = np.delete(A, rows_to_be_deleted,0)\n",
    "A = np.delete(A, rows_to_be_deleted,1)\n",
    "y = df_merged_total[\"winner\"]\n",
    "y = np.delete(np.array(y), rows_to_be_deleted,0) \n",
    "X_total = X_total.values\n",
    "X_total = np.delete(np.array(X_total), rows_to_be_deleted,0)\n",
    "# compute lamb and U\n",
    "laplacian = compute_laplacian(A, normalize=True)\n",
    "lamb, U = spectral_decomposition(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2939\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "n_nodes = A.shape[0]\n",
    "ideal_lp = np.ones((n_nodes,)) \n",
    "ideal_lp[lamb >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp = ideal_graph_filter(y,ideal_lp,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows_to_be_deleted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = np.arange(10)\n",
    "n = int(len(y)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.9019697101103207\n",
      "The variance is  0.008234275548126271\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean, accuracy_var = pred_iteration(A,iters, y, n, x_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for = df_merged_for.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_for = df_merged_for.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_for['agi'] = (X_for['agi'] - X_for['agi'].mean()) / X_for['agi'].std()\n",
    "X_for['prop_ret/exempt'] = X_for['n1'] / X_for['n2']\n",
    "X_for = X_for.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_for = epsilon_similarity_graph(X_for, sigma=0.6675252605174871*0.1, epsilon=0.5)\n",
    "#plt.spy(adjacency_RGB_for)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_for = adjacency_RGB_for.copy()\n",
    "rows_to_be_deleted_for = np.where(np.sum(adjacency_RGB_for,1) == 0)\n",
    "A_for = np.delete(A_for, rows_to_be_deleted_for,0)\n",
    "A_for = np.delete(A_for, rows_to_be_deleted_for,1)\n",
    "y_for = df_merged_for[\"winner\"]\n",
    "y_for = np.delete(np.array(y_for), rows_to_be_deleted_for,0) \n",
    "\n",
    "X_for = X_for.values\n",
    "X_for = np.delete(np.array(X_for), rows_to_be_deleted_for,0) \n",
    "\n",
    "# compute lamb and U\n",
    "laplacian_for = compute_laplacian(A_for, normalize=True)\n",
    "lamb_for, U_for = spectral_decomposition(laplacian_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_for = np.ones((A_for.shape[0],)) \n",
    "ideal_lp_for[lamb_for >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_for = ideal_graph_filter(y_for,ideal_lp_for,U_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_for = np.arange(10)\n",
    "n_for = int(len(y_for)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.8413599105861337\n",
      "The variance is  0.02580566291784558\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean_for, accuracy_var_for = pred_iteration(A_for,iters_for, y_for, n_for, x_lp_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_us = df_merged_us.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_us = df_merged_us.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_us['agi'] = (X_us['agi'] - X_us['agi'].mean()) / X_us['agi'].std()\n",
    "X_us['prop_ret/exempt'] = X_us['n1'] / X_us['n2']\n",
    "X_us = X_us.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_us = epsilon_similarity_graph(X_us, sigma=0.5310405705207334*0.1, epsilon=0.5)\n",
    "#plt.spy(adjacency_RGB_us)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_us = adjacency_RGB_us.copy()\n",
    "rows_to_be_deleted_us = np.where(np.sum(adjacency_RGB_us,1) == 0)\n",
    "A_us = np.delete(A_us, rows_to_be_deleted_us,0)\n",
    "A_us = np.delete(A_us, rows_to_be_deleted_us,1)\n",
    "y_us = df_merged_us[\"winner\"]\n",
    "y_us = np.delete(np.array(y_us), rows_to_be_deleted_us,0) \n",
    "\n",
    "X_us = X_us.values\n",
    "X_us = np.delete(np.array(X_us), rows_to_be_deleted_us,0) \n",
    "# compute lamb and U\n",
    "laplacian_us = compute_laplacian(A_us, normalize=True)\n",
    "lamb_us, U_us = spectral_decomposition(laplacian_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2921\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_us = np.ones((A_us.shape[0],)) \n",
    "ideal_lp_us[lamb_us >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_us = ideal_graph_filter(y_us,ideal_lp_us,U_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_us = np.arange(10)\n",
    "n_us = int(len(y_us)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.9028313817355549\n",
      "The variance is  0.0052804173512027595\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean_us, accuracy_var_us = pred_iteration(A_us,iters_us, y_us, n_us, x_lp_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer avec la version sans filtrage pour avoir combien on améliore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9ebde5a8b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "from dgl.data.citation_graph import load_cora\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianPolynomial(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats: int,\n",
    "                 out_feats: int,\n",
    "                 k: int,\n",
    "                 dropout_prob: float,\n",
    "                 norm=True):\n",
    "        super().__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self._k = k\n",
    "        self._norm = norm\n",
    "        # Contains the weights learned by the Laplacian polynomial\n",
    "        self.pol_weights = nn.Parameter(torch.Tensor(self._k + 1))\n",
    "        # Contains the weights learned by the logistic regression (without bias)\n",
    "        self.logr_weights = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        torch.manual_seed(0)\n",
    "        torch.nn.init.xavier_uniform_(self.logr_weights, gain=0.01)\n",
    "        torch.nn.init.normal_(self.pol_weights, mean=0.0, std=1e-3)\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        r\"\"\"Compute graph convolution.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        * Input shape: :math:`(N, *, \\text{in_feats})` where * means any number of additional\n",
    "          dimensions, :math:`N` is the number of nodes.\n",
    "        * Output shape: :math:`(N, *, \\text{out_feats})` where all but the last dimension are\n",
    "          the same shape as the input.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph (DGLGraph) : The graph.\n",
    "        feat (torch.Tensor): The input feature\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (torch.Tensor) The output feature\n",
    "        \"\"\"\n",
    "        feat = self.dropout(feat)\n",
    "        graph = graph.local_var()\n",
    "        \n",
    "        # D^(-1/2)\n",
    "        norm = torch.pow(graph.in_degrees().float().clamp(min=1), -0.5)\n",
    "        shp = norm.shape + (1,) * (feat.dim() - 1)\n",
    "        norm = torch.reshape(norm, shp)\n",
    "\n",
    "        # mult W first to reduce the feature size for aggregation.\n",
    "        feat = torch.matmul(feat, self.logr_weights)\n",
    "\n",
    "        result = self.pol_weights[0] * feat.clone()\n",
    "\n",
    "        for i in range(1, self._k + 1):\n",
    "            old_feat = feat.clone()\n",
    "            if self._norm:\n",
    "                feat = feat * norm\n",
    "            graph.ndata['h'] = feat\n",
    "            # Feat is not modified in place\n",
    "            graph.update_all(fn.copy_src(src='h', out='m'),\n",
    "                             fn.sum(msg='m', out='h'))\n",
    "            if self._norm:\n",
    "                graph.ndata['h'] = graph.ndata['h'] * norm\n",
    "\n",
    "            feat = old_feat - graph.ndata['h']\n",
    "            result += self.pol_weights[i] * feat\n",
    "\n",
    "        return result\n",
    "\n",
    "    def extra_repr(self):\n",
    "        \"\"\"Set the extra representation of the module,\n",
    "        which will come into effect when printing the model.\n",
    "        \"\"\"\n",
    "        summary = 'in={_in_feats}, out={_out_feats}'\n",
    "        summary += ', normalization={_norm}'\n",
    "        return summary.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, features, labels, loss_fcn, train_mask, optimizer):\n",
    "    model.train()  # Activate dropout\n",
    "    \n",
    "    logits = model(g, features)\n",
    "    loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()  # Deactivate dropout\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)[mask]  # only compute the evaluation set\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "    \n",
    "def polynomial_graph_filter(coeff: np.array, laplacian: np.ndarray):\n",
    "    \"\"\" Return the laplacian polynomial with coefficients 'coeff'. \"\"\"\n",
    "    # Your code here\n",
    "    res = np.zeros_like(laplacian)\n",
    "    for i in range (len(coeff)):\n",
    "        res += coeff[i] * np.linalg.matrix_power(laplacian, i)\n",
    "    return res\n",
    "\n",
    "def polynomial_graph_filter_response(coeff: np.array, lam: np.ndarray):\n",
    "    \"\"\" Return an array of the same shape as lam.\n",
    "        response[i] is the spectral response at frequency lam[i]. \"\"\"\n",
    "    # Your code here\n",
    "    res = np.zeros((len(coeff),len(lam)))\n",
    "    for i in range(len(coeff)):\n",
    "        res[i] = coeff[i] * (lam**i)\n",
    "    res = np.sum(res,axis =0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gcn(iters,X,y,A,laplacian,lamb,U):\n",
    "    f1_scores = []\n",
    "    print(\"Computing\")\n",
    "    for i in range(iters):\n",
    "        if( i != 0 and i%(iters*0.1) == 0):\n",
    "            print(str(int(i*100/iters))+\" %\")\n",
    "        # Some basic settings\n",
    "        features = torch.FloatTensor(X)\n",
    "        labels = torch.LongTensor(y) \n",
    "        in_feats = features.shape[1]  # 2\n",
    "        n_classes = 2\n",
    "        n_edges = int(A.sum() // 2)\n",
    "        pol_order = 3\n",
    "        lr = 0.2\n",
    "        weight_decay = 5e-6\n",
    "        n_epochs = 500\n",
    "        p_dropout = 0.8\n",
    "\n",
    "        # prepare for masking\n",
    "        n_points = X.shape[0]\n",
    "        indices = np.arange(n_points)\n",
    "        np.random.shuffle(indices)\n",
    "        split_t = int(n_points*0.2)\n",
    "        test_idx = indices[:split_t]\n",
    "        train_idx = indices[split_t:]\n",
    "        train_mask = np.zeros(n_points)\n",
    "        train_mask[train_idx] = 1\n",
    "        test_mask = np.zeros(n_points)\n",
    "        test_mask[test_idx] = 1\n",
    "        graph = nx.from_numpy_matrix(A)\n",
    "        adjacency = np.asarray(nx.to_numpy_matrix(graph))\n",
    "        n_nodes = adjacency.shape[0]\n",
    "        lam_max = np.max(lamb)\n",
    "\n",
    "\n",
    "        graph = DGLGraph(graph)\n",
    "        model = LaplacianPolynomial(in_feats, n_classes, pol_order, p_dropout)\n",
    "\n",
    "        loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=lr,\n",
    "                                     weight_decay=weight_decay)\n",
    "\n",
    "        dur = []\n",
    "        for epoch in range(50):\n",
    "            loss = train(model, graph, features, labels, loss_fcn, train_mask, optimizer)\n",
    "\n",
    "        coeff_gcn =  model.pol_weights.detach().numpy()\n",
    "        graph_gcn_filter = polynomial_graph_filter(coeff_gcn, laplacian)\n",
    "        features_gcn = graph_gcn_filter @ features.numpy()\n",
    "        train_mask = torch.BoolTensor(train_mask) \n",
    "        test_mask = torch.BoolTensor(test_mask)\n",
    "        train_features_gcn = features_gcn[train_mask,:]\n",
    "        train_labels = labels[train_mask]\n",
    "        test_features_gcn = features_gcn[test_mask,:]\n",
    "        test_labels = labels[test_mask]\n",
    "        print(train_labels)\n",
    "        model =  LogisticRegression(C=1000,penalty = 'l2',solver='liblinear', multi_class='auto',max_iter = 2000)\n",
    "        model.fit(train_features_gcn, train_labels)\n",
    "        \n",
    "        test_pred = model.predict(test_features_gcn)\n",
    "        #test_acc =  model.score(test_features_gcn,test_labels)  \n",
    "        #accuracy.append(test_acc)\n",
    "        print(test_pred)\n",
    "        print(\"---\")\n",
    "        f1_scores.append(sm.f1_score(test_labels,test_pred))\n",
    "        #for i in range(len(pred_thres)):\n",
    "        #    if(pred_thres[i] == truth[i]):\n",
    "        #        right_pred.append(i)\n",
    "        #accuracy.append( len(right_pred)/len(test_idx))\n",
    "        \n",
    "    print(\"100 %\")\n",
    "    mean = np.mean(f1_scores)\n",
    "    var = np.std(f1_scores)\n",
    "    print(\"The mean is \",mean)\n",
    "    print(\"The variance is \",var)\n",
    "    return mean,var        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "        1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        1,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       -1,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,\n",
       "        1,  0,  1,  0,  0,  0, -1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "        0,  0,  0,  0,  0,  0,  1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  1,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  1,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,\n",
       "        1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "10%\n",
      "20%\n",
      "30%\n",
      "40%\n",
      "50%\n",
      "60%\n",
      "70%\n",
      "80%\n",
      "90%\n",
      "The mean is  0.8863869863013699\n",
      "The variance is  0.009690555491542241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8863869863013699, 0.009690555491542241)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_us,var_us = apply_gcn(20,X_us,y_us,A_us,laplacian_us,lamb_us,U_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "10%\n",
      "20%\n",
      "30%\n",
      "40%\n",
      "50%\n",
      "60%\n",
      "70%\n",
      "80%\n",
      "90%\n",
      "The mean is  0.910817717206133\n",
      "The variance is  0.010885247108108901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.910817717206133, 0.010885247108108901)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_total,var_total = apply_gcn(20,X_total,y,A,laplacian,lamb,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result \n",
    "accuracy: `mean-var`\n",
    "\n",
    "            Total      For        Us\n",
    "            \n",
    "`GCN :     0.91-0.01  0.71-0.04  0.88-0.01`\n",
    "\n",
    "`Fourier : 0.82-0.01  0.74-0.05  0.82-0.01`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit? => comparer les ecarts de scores entre train set et test set\n",
    "# ne petmettre pas de trouver les patterns\n",
    "\n",
    "\n",
    "# metric when data note balanced: F1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
