{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import scipy as sci\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics as sm\n",
    "from utils import * # contains all helper functions used in the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_migrations = pd.read_csv(\"./NTDS_Data/countyinflow1516.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_migrations = pd.read_csv(\"./NTDS_Data/countyinflow1516.csv\" )\n",
    "\n",
    "# keep only summury information of each county\n",
    "df_migrations = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration\")]\n",
    "\n",
    "# create the combined fips county number \n",
    "df_migrations['statefips_str'] = df_migrations['y2_statefips'].apply(lambda x : str(x).zfill(2))\n",
    "df_migrations['countyfips_str'] = df_migrations['y2_countyfips'].apply(lambda x : str(x).zfill(3))\n",
    "df_migrations['combined_fips'] = df_migrations['statefips_str'].apply(lambda x: x.lstrip('0')) + df_migrations['countyfips_str']\n",
    "\n",
    "# drop useless information \n",
    "df_migrations = df_migrations.drop(columns=[\"y2_statefips\", \"y2_countyfips\", \"y1_statefips\", \"y1_countyfips\", \"y1_state\", \"statefips_str\", \"countyfips_str\"])\n",
    "\n",
    "# seperate each possible migration into three dataframe \n",
    "df_migration_total = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US and Foreign\")]\n",
    "df_migrations['y1_countyname'] = df_migrations['y1_countyname'].apply(lambda x : x if x.find(\"County Total Migration-US and Foreign\") == -1 else \"County Total Migration Both\")\n",
    "df_migration_us = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US\")]\n",
    "df_migration_for = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-Foreign\")]\n",
    "\n",
    "# drop the name of the column \n",
    "df_migration_total = df_migration_total.drop(columns=[\"y1_countyname\"])\n",
    "df_migration_us = df_migration_us.drop(columns=[\"y1_countyname\"])\n",
    "df_migration_for = df_migration_for.drop(columns=[\"y1_countyname\"])\n",
    "\n",
    "# remove nodes where data is undefined undefined data by zero\n",
    "df_migration_total = df_migration_total[df_migration_total['n1'] != -1]\n",
    "df_migration_us = df_migration_us[df_migration_us['n1'] != -1]\n",
    "df_migration_for = df_migration_for[df_migration_for['n1'] != -1]\n",
    "\n",
    "# convert combined fips to int64\n",
    "df_migration_total['combined_fips'] = df_migration_total['combined_fips'].astype('int64')\n",
    "df_migration_us['combined_fips'] = df_migration_us['combined_fips'].astype('int64')\n",
    "df_migration_for['combined_fips'] = df_migration_for['combined_fips'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presidential_result = pd.read_csv(\"./NTDS_Data/2016_US_County_Level_Presidential_Results.csv\" )\n",
    "df_presidential_result = df_presidential_result.drop(columns=[\"Unnamed: 0\",\"votes_dem\", \"votes_gop\", \"total_votes\", \"diff\", \"per_point_diff\", \"state_abbr\", \"county_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataset and drop useless column, add a new column winner \n",
    "df_merged_total = pd.merge(df_migration_total, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_us = pd.merge(df_migration_us, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_for = pd.merge(df_migration_for, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_total['difference'] = df_merged_total['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_us['difference'] = df_merged_us['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_for['difference'] = df_merged_for['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_total['winner'] = df_merged_total['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_us['winner'] = df_merged_us['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_for['winner'] = df_merged_for['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_total = df_merged_total.drop(columns=['difference'])\n",
    "df_merged_us = df_merged_us.drop(columns=['difference'])\n",
    "df_merged_for = df_merged_for.drop(columns=['difference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division by zero in normalized lapacien computation\n",
    "\n",
    "- some nodes do not have any connection in the graph => create new adjacency matrix A by deleting these nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = df_merged_total.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_total = df_merged_total.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_total['agi'] = (X_total['agi'] - X_total['agi'].mean()) / X_total['agi'].std()\n",
    "X_total['prop_ret/exempt'] = X_total['n1'] / X_total['n2']\n",
    "X_total = X_total.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_total = epsilon_similarity_graph(X_total, sigma=0.5284353963018223*0.1, epsilon=0.2)\n",
    "#plt.spy(adjacency_RGB_total)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly choose some points for prediction use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A = adjacency_RGB_total.copy()\n",
    "#rows_to_be_deleted = np.where(np.sum(adjacency_RGB_total,1) == 0)\n",
    "#A = np.delete(A, rows_to_be_deleted,0)\n",
    "#A = np.delete(A, rows_to_be_deleted,1)\n",
    "y = df_merged_total[\"winner\"].copy()\n",
    "#y = np.delete(np.array(y), rows_to_be_deleted,0) \n",
    "X_total = X_total.values\n",
    "#X_total = np.delete(np.array(X_total), rows_to_be_deleted,0)\n",
    "# compute lamb and U\n",
    "laplacian = compute_laplacian(A, normalize=True)\n",
    "lamb, U = spectral_decomposition(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "n_nodes = A.shape[0]\n",
    "ideal_lp = np.ones((n_nodes,)) \n",
    "ideal_lp[lamb >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp = ideal_graph_filter(y.copy(),ideal_lp,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = 10\n",
    "n = int(len(y)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.9297656318913955\n",
      "The variance is  0.005463285965821614\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean, accuracy_var = pred_iteration(A,iters, y, n, x_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for = df_merged_for.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_for = df_merged_for.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_for['agi'] = (X_for['agi'] - X_for['agi'].mean()) / X_for['agi'].std()\n",
    "X_for['prop_ret/exempt'] = X_for['n1'] / X_for['n2']\n",
    "X_for = X_for.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_for = epsilon_similarity_graph(X_for, sigma=0.6675252605174871*0.1, epsilon=0.5)\n",
    "#plt.spy(adjacency_RGB_for)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_for = adjacency_RGB_for.copy()\n",
    "y_for = df_merged_for[\"winner\"].copy()\n",
    "\n",
    "X_for = X_for.values\n",
    "\n",
    "# compute lamb and U\n",
    "laplacian_for = compute_laplacian(A_for, normalize=True)\n",
    "lamb_for, U_for = spectral_decomposition(laplacian_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_for = np.ones((A_for.shape[0],)) \n",
    "ideal_lp_for[lamb_for >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_for = ideal_graph_filter(y_for.copy(),ideal_lp_for,U_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_for = 20\n",
    "n_for = int(len(y_for)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.8607594936708861\n",
      "The variance is  0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean_for, accuracy_var_for = pred_iteration(A_for,iters_for, y_for, n_for, x_lp_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_us = df_merged_us.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_us = df_merged_us.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_us['agi'] = (X_us['agi'] - X_us['agi'].mean()) / X_us['agi'].std()\n",
    "X_us['prop_ret/exempt'] = X_us['n1'] / X_us['n2']\n",
    "X_us = X_us.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_us = epsilon_similarity_graph(X_us, sigma=0.5310405705207334*0.1, epsilon=0.5)\n",
    "#plt.spy(adjacency_RGB_us)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_us = adjacency_RGB_us.copy()\n",
    "y_us = df_merged_us[\"winner\"].copy()\n",
    "\n",
    "X_us = X_us.values\n",
    "# compute lamb and U\n",
    "laplacian_us = compute_laplacian(A_us, normalize=True)\n",
    "lamb_us, U_us = spectral_decomposition(laplacian_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_us = np.ones((A_us.shape[0],)) \n",
    "ideal_lp_us[lamb_us >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_us = ideal_graph_filter(y_us.copy(),ideal_lp_us,U_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_us = 1\n",
    "n_us = int(len(y_us)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.9283018867924528\n",
      "The variance is  0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean_us, accuracy_var_us = pred_iteration(A_us,iters_us, y_us, n_us, x_lp_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer avec la version sans filtrage pour avoir combien on am√©liore\n",
    "# avec quel method de coup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f267024b690>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "from dgl.data.citation_graph import load_cora\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing\n",
      "100 %\n",
      "The mean of f1 score is  0.7619047619047619\n",
      "The variance of f1 score is  0.0\n"
     ]
    }
   ],
   "source": [
    "mean_for,var_for = apply_gcn(1,X_for,y_for,A_for,laplacian_for,lamb_for,U_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing\n",
      "100 %\n",
      "The mean of f1 score is  0.9341983317886932\n",
      "The variance of f1 score is  0.0\n"
     ]
    }
   ],
   "source": [
    "mean_total,var_total = apply_gcn(1,X_total,y,A,laplacian,lamb,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing\n",
      "100 %\n",
      "The mean of f1 score is  0.929368029739777\n",
      "The variance of f1 score is  0.0\n"
     ]
    }
   ],
   "source": [
    "mean_us,var_us = apply_gcn(1,X_us,y_us,A_us,laplacian_us,lamb_us,U_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result \n",
    "accuracy: `mean-var` for 20 iterations\n",
    "\n",
    "              Total         For           Us\n",
    "            \n",
    "`GCN :     0.925-0.008  0.835-0.025  0.929-0.008`\n",
    "\n",
    "`Fourier : 0.931-0.008  0.855-0.023  0.928-0.007`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit? => comparer les ecarts de scores entre train set et test set\n",
    "# ne petmettre pas de trouver les patterns\n",
    "\n",
    "\n",
    "# metric when data note balanced: F1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
