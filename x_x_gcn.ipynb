{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import scipy as sci\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics as sm\n",
    "from utils import * # contains all helper functions used in the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_migrations = pd.read_csv(\"./NTDS_Data/countyinflow1516.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_migrations = pd.read_csv(\"./NTDS_Data/countyinflow1516.csv\" )\n",
    "\n",
    "# keep only summury information of each county\n",
    "df_migrations = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration\")]\n",
    "\n",
    "# create the combined fips county number \n",
    "df_migrations['statefips_str'] = df_migrations['y2_statefips'].apply(lambda x : str(x).zfill(2))\n",
    "df_migrations['countyfips_str'] = df_migrations['y2_countyfips'].apply(lambda x : str(x).zfill(3))\n",
    "df_migrations['combined_fips'] = df_migrations['statefips_str'].apply(lambda x: x.lstrip('0')) + df_migrations['countyfips_str']\n",
    "\n",
    "# drop useless information \n",
    "df_migrations = df_migrations.drop(columns=[\"y2_statefips\", \"y2_countyfips\", \"y1_statefips\", \"y1_countyfips\", \"y1_state\", \"statefips_str\", \"countyfips_str\"])\n",
    "\n",
    "# seperate each possible migration into three dataframe \n",
    "df_migration_total = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US and Foreign\")]\n",
    "df_migrations['y1_countyname'] = df_migrations['y1_countyname'].apply(lambda x : x if x.find(\"County Total Migration-US and Foreign\") == -1 else \"County Total Migration Both\")\n",
    "df_migration_us = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US\")]\n",
    "df_migration_for = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-Foreign\")]\n",
    "\n",
    "# drop the name of the column \n",
    "df_migration_total = df_migration_total.drop(columns=[\"y1_countyname\"])\n",
    "df_migration_us = df_migration_us.drop(columns=[\"y1_countyname\"])\n",
    "df_migration_for = df_migration_for.drop(columns=[\"y1_countyname\"])\n",
    "\n",
    "# remove nodes where data is undefined undefined data by zero\n",
    "df_migration_total = df_migration_total[df_migration_total['n1'] != -1]\n",
    "df_migration_us = df_migration_us[df_migration_us['n1'] != -1]\n",
    "df_migration_for = df_migration_for[df_migration_for['n1'] != -1]\n",
    "\n",
    "# convert combined fips to int64\n",
    "df_migration_total['combined_fips'] = df_migration_total['combined_fips'].astype('int64')\n",
    "df_migration_us['combined_fips'] = df_migration_us['combined_fips'].astype('int64')\n",
    "df_migration_for['combined_fips'] = df_migration_for['combined_fips'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presidential_result = pd.read_csv(\"./NTDS_Data/2016_US_County_Level_Presidential_Results.csv\" )\n",
    "df_presidential_result = df_presidential_result.drop(columns=[\"Unnamed: 0\",\"votes_dem\", \"votes_gop\", \"total_votes\", \"diff\", \"per_point_diff\", \"state_abbr\", \"county_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataset and drop useless column, add a new column winner \n",
    "df_merged_total = pd.merge(df_migration_total, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_us = pd.merge(df_migration_us, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_for = pd.merge(df_migration_for, df_presidential_result, on=\"combined_fips\", how='inner')\n",
    "df_merged_total['difference'] = df_merged_total['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_us['difference'] = df_merged_us['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_for['difference'] = df_merged_for['per_dem'] - df_merged_total['per_gop']\n",
    "df_merged_total['winner'] = df_merged_total['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_us['winner'] = df_merged_us['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_for['winner'] = df_merged_for['difference'].apply(lambda x : -1 if x > 0 else 1)\n",
    "df_merged_total = df_merged_total.drop(columns=['difference'])\n",
    "df_merged_us = df_merged_us.drop(columns=['difference'])\n",
    "df_merged_for = df_merged_for.drop(columns=['difference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division by zero in normalized lapacien computation\n",
    "\n",
    "- some nodes do not have any connection in the graph => create new adjacency matrix A by deleting these nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = df_merged_total.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_total = df_merged_total.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_total['agi'] = (X_total['agi'] - X_total['agi'].mean()) / X_total['agi'].std()\n",
    "X_total['prop_ret/exempt'] = X_total['n1'] / X_total['n2']\n",
    "X_total = X_total.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_total = epsilon_similarity_graph(X_total, sigma=0.5284353963018223*0.1, epsilon=0.2)\n",
    "#plt.spy(adjacency_RGB_total)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly choose some points for prediction use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A = adjacency_RGB_total.copy()\n",
    "#rows_to_be_deleted = np.where(np.sum(adjacency_RGB_total,1) == 0)\n",
    "#A = np.delete(A, rows_to_be_deleted,0)\n",
    "#A = np.delete(A, rows_to_be_deleted,1)\n",
    "y = df_merged_total[\"winner\"].copy()\n",
    "#y = np.delete(np.array(y), rows_to_be_deleted,0) \n",
    "X_total = X_total.values\n",
    "#X_total = np.delete(np.array(X_total), rows_to_be_deleted,0)\n",
    "# compute lamb and U\n",
    "laplacian = compute_laplacian(A, normalize=True)\n",
    "lamb, U = spectral_decomposition(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "n_nodes = A.shape[0]\n",
    "ideal_lp = np.ones((n_nodes,)) \n",
    "ideal_lp[lamb >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp = ideal_graph_filter(y.copy(),ideal_lp,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = 10\n",
    "n = int(len(y)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.9297656318913955\n",
      "The variance is  0.005463285965821614\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean, accuracy_var = pred_iteration(A,iters, y, n, x_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for = df_merged_for.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_for = df_merged_for.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_for['agi'] = (X_for['agi'] - X_for['agi'].mean()) / X_for['agi'].std()\n",
    "X_for['prop_ret/exempt'] = X_for['n1'] / X_for['n2']\n",
    "X_for = X_for.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_for = epsilon_similarity_graph(X_for, sigma=0.6675252605174871*0.1, epsilon=0.5)\n",
    "#plt.spy(adjacency_RGB_for)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_for = adjacency_RGB_for.copy()\n",
    "y_for = df_merged_for[\"winner\"].copy()\n",
    "\n",
    "X_for = X_for.values\n",
    "\n",
    "# compute lamb and U\n",
    "laplacian_for = compute_laplacian(A_for, normalize=True)\n",
    "lamb_for, U_for = spectral_decomposition(laplacian_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_for = np.ones((A_for.shape[0],)) \n",
    "ideal_lp_for[lamb_for >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_for = ideal_graph_filter(y_for.copy(),ideal_lp_for,U_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_for = 20\n",
    "n_for = int(len(y_for)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "450    1\n",
      "451    1\n",
      "452    1\n",
      "453    1\n",
      "454    1\n",
      "Name: winner, Length: 455, dtype: int64\n",
      "-99\n",
      "The mean is  0.8486809408603457\n",
      "The variance is  0.03414853457970139\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean_for, accuracy_var_for = pred_iteration(A_for,iters_for, y_for, n_for, x_lp_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_us = df_merged_us.drop(columns=['combined_fips', 'per_dem', 'per_gop', 'winner'])\n",
    "nodes_us = df_merged_us.drop(columns=['n1', 'n2', 'agi', 'per_dem', 'per_gop']).values\n",
    "X_us['agi'] = (X_us['agi'] - X_us['agi'].mean()) / X_us['agi'].std()\n",
    "X_us['prop_ret/exempt'] = X_us['n1'] / X_us['n2']\n",
    "X_us = X_us.drop(columns=['n1', 'n2'])\n",
    "adjacency_RGB_us = epsilon_similarity_graph(X_us, sigma=0.5310405705207334*0.1, epsilon=0.5)\n",
    "#plt.spy(adjacency_RGB_us)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_us = adjacency_RGB_us.copy()\n",
    "y_us = df_merged_us[\"winner\"].copy()\n",
    "\n",
    "X_us = X_us.values\n",
    "# compute lamb and U\n",
    "laplacian_us = compute_laplacian(A_us, normalize=True)\n",
    "lamb_us, U_us = spectral_decomposition(laplacian_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_us = np.ones((A_us.shape[0],)) \n",
    "ideal_lp_us[lamb_us >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_us = ideal_graph_filter(y_us.copy(),ideal_lp_us,U_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_us = 1\n",
    "n_us = int(len(y_us)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  0.9283018867924528\n",
      "The variance is  0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_mean_us, accuracy_var_us = pred_iteration(A_us,iters_us, y_us, n_us, x_lp_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer avec la version sans filtrage pour avoir combien on améliore\n",
    "# avec quel method de coup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f267024b690>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "from dgl.data.citation_graph import load_cora\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing\n",
      "100 %\n",
      "The mean of f1 score is  0.7619047619047619\n",
      "The variance of f1 score is  0.0\n"
     ]
    }
   ],
   "source": [
    "mean_for,var_for = apply_gcn(1,X_for,y_for,A_for,laplacian_for,lamb_for,U_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing\n",
      "100 %\n",
      "The mean of f1 score is  0.9341983317886932\n",
      "The variance of f1 score is  0.0\n"
     ]
    }
   ],
   "source": [
    "mean_total,var_total = apply_gcn(1,X_total,y,A,laplacian,lamb,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing\n",
      "100 %\n",
      "The mean of f1 score is  0.929368029739777\n",
      "The variance of f1 score is  0.0\n"
     ]
    }
   ],
   "source": [
    "mean_us,var_us = apply_gcn(1,X_us,y_us,A_us,laplacian_us,lamb_us,U_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result \n",
    "accuracy: `mean-var` for 20 iterations\n",
    "\n",
    "              Total         For           Us\n",
    "            \n",
    "`GCN :     0.925-0.008  0.835-0.025  0.929-0.008`\n",
    "\n",
    "`Fourier : 0.931-0.008  0.855-0.023  0.928-0.007`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit? => comparer les ecarts de scores entre train set et test set\n",
    "# ne petmettre pas de trouver les patterns\n",
    "\n",
    "\n",
    "# metric when data note balanced: F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another adjacency matrix with migration flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_migrations = pd.read_csv(\"NTDS_Data/countyinflow1516.csv\" )\n",
    "\n",
    "\n",
    "# create the combined fips county number of destination\n",
    "df_migrations['statefips_str'] = df_migrations['y2_statefips'].apply(lambda x : str(x).zfill(2))\n",
    "df_migrations['countyfips_str'] = df_migrations['y2_countyfips'].apply(lambda x : str(x).zfill(3))\n",
    "df_migrations['combined_fips-destination'] = df_migrations['statefips_str'].apply(lambda x: x.lstrip('0')) + df_migrations['countyfips_str']\n",
    "\n",
    "# create the combined fips county number of source\n",
    "df_migrations['statefips_str1'] = df_migrations['y1_statefips'].apply(lambda x : str(x).zfill(2))\n",
    "df_migrations['countyfips_str1'] = df_migrations['y1_countyfips'].apply(lambda x : str(x).zfill(3))\n",
    "df_migrations['combined_fips-source'] = df_migrations['statefips_str1'].apply(lambda x: x.lstrip('0')) + df_migrations['countyfips_str1']\n",
    "\n",
    "# Experimenting with parametres(not important)\n",
    "#new_df = df[(df['WindSpeed']>4) & (df['Temperature']>30)]\n",
    "#df_migrations2 = df_migrations[df_migrations['y1_countyname'].str.contains(\"County Total Migration-US and Foreign\")]\n",
    "#df_migrations3 = df_migrations[(df_migrations['y1_statefips']== 96) & (df_migrations['y2_countyfips']!= 0)]\n",
    "\n",
    "#Cleaning the data to have only source and origin counties and unemployment rate as a new column\n",
    "df_migrations = df_migrations[df_migrations['y1_statefips']<=56]\n",
    "df_migrations[\"Unemployment rate\"] = df_migrations[\"n1\"]/(df_migrations[\"n2\"] +df_migrations[\"n1\"] )\n",
    "df_migrations1 = df_migrations[df_migrations['combined_fips-destination'] ==df_migrations['combined_fips-source']]  # keeping Unemployment rate of non migrants\n",
    "  \n",
    "\n",
    "\n",
    " #drop useless information \n",
    "df_migrations = df_migrations.drop(columns=[\"y1_countyname\",\"y2_statefips\", \"y2_countyfips\", \"y1_statefips\", \"y1_countyfips\", \"y1_state\", \"statefips_str\", \"countyfips_str\",\"statefips_str1\", \"countyfips_str1\"])\n",
    "df_migrations1 = df_migrations1.drop(columns=[\"y1_countyname\",\"y2_statefips\", \"y2_countyfips\", \"y1_statefips\", \"y1_countyfips\", \"y1_state\", \"statefips_str\", \"countyfips_str\",\"statefips_str1\", \"countyfips_str1\"])\n",
    "df_migrations1 =df_migrations1.drop(columns=[\"agi\",\"combined_fips-source\"])\n",
    "\n",
    "\n",
    "\n",
    "# remove nodes where data is undefined undefined data by zero\n",
    "df_migrations = df_migrations[df_migrations['n1'] != -1]\n",
    "df_migrations1 = df_migrations1[df_migrations1['n1'] != -1]\n",
    "#df_migrations3 = df_migrations3[df_migrations3['n1'] != -1]\n",
    "\n",
    "# convert combined fips to int64\n",
    "df_migrations['combined_fips-destination'] = df_migrations['combined_fips-destination'].astype('int64')\n",
    "df_migrations['combined_fips-source'] = df_migrations['combined_fips-source'].astype('int64')\n",
    "df_migrations1['combined_fips-destination'] = df_migrations1['combined_fips-destination'].astype('int64')\n",
    "\n",
    "#print(df_migrations1)\n",
    "df_migrations1= df_migrations1.drop(columns=[\"n1\",\"n2\",\"combined_fips-destination\"])\n",
    "\n",
    "#extracting the combined fips destination and combined fips source for graph in form of numpy arrays\n",
    "df_graph= df_migrations.drop(columns=[\"n1\",\"n2\",\"agi\",\"Unemployment rate\"])\n",
    "\n",
    "arr = df_graph.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presidential_result = pd.read_csv(\"NTDS_Data/2016_US_County_Level_Presidential_Results.csv\" )\n",
    "df_presidential_result = df_presidential_result.drop(columns=[\"Unnamed: 0\",\"votes_dem\", \"votes_gop\", \"total_votes\", \"diff\", \"per_point_diff\", \"state_abbr\", \"county_name\"])\n",
    "\n",
    "#Sorting according to the fips code to be consistent with the migration data by IRS\n",
    "df_presidential_result = df_presidential_result.sort_values(by=['combined_fips'])\n",
    "\n",
    "#Adding a new column of the winners with -1 corresponding to democrat and 1 to republican\n",
    "\n",
    "df_presidential_result[\"Winner\"] =  np.where((df_presidential_result['per_dem'] > df_presidential_result['per_gop'])\n",
    "                     , -1, 1)\n",
    "\n",
    "#print(df_presidential_result)\n",
    "df_presidential_result = df_presidential_result.drop(columns=[\"per_dem\",\"per_gop\",\"combined_fips\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_nodes = np.unique(arr)\n",
    "#print(possible_nodes)\n",
    "A_migr = np.zeros((len(possible_nodes), len(possible_nodes))) \n",
    "\n",
    "for dest, source in arr : \n",
    "     \n",
    "    i = np.where(possible_nodes == dest)\n",
    "    #print(i)\n",
    "    j = np.where(possible_nodes == source)\n",
    "    #print(j)\n",
    "    A_migr[j[0], i[0]] = 1\n",
    " \n",
    "\n",
    "# Creating a dictionary of attribute of Unemployment rate\n",
    "#y_unemployment_rate = df_migrations1.to_numpy()\n",
    "#d = dict(enumerate(z.flatten(), 0))\n",
    "\n",
    "#Creating a dictionary of attribute of county election result\n",
    "#y_presidential_result = df_presidential_result.to_numpy()\n",
    "#d2 = dict(enumerate(z.flatten(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare A and x(signal)\n",
    "A_migration = A_migr.copy()\n",
    "# define two different targets for migration adjacency matrix\n",
    "y_unemployment_rate = df_migrations1[\"Unemployment rate\"].copy()\n",
    "y_presidential_result = df_presidential_result[\"Winner\"].copy()\n",
    "# compute lamb and U\n",
    "laplacian_migration = compute_laplacian(A_migration, normalize=True)\n",
    "lamb_migration, U_migration = spectral_decomposition(laplacian_migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3141\n"
     ]
    }
   ],
   "source": [
    "# prepare filter\n",
    "ideal_lp_migration = np.ones((A_migration.shape[0],)) \n",
    "ideal_lp_migration[lamb_migration >= 0.1] = 0   # to tune\n",
    "# apply filter\n",
    "x_lp_migration = ideal_graph_filter(y_unemployment_rate.copy(),ideal_lp_migration,U_migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 1\n",
    "n = int(len(y_presidential_result)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation the prediction using Fourier analysis\n",
    "def pred_iteration(A,iters, y, n, filtered_x_lp):\n",
    "    f1_scores =[]\n",
    "    y_ = y.copy() # this is training data\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # choose randomly n indices to masking, for evaluating use\n",
    "        test_idx = np.random.choice(np.arange(len(y_)),n,replace = False)\n",
    "        # masking some winner\n",
    "        y_[2828]=0\n",
    "        # prepare ground truth labels\n",
    "        truth = (y[test_idx]).values\n",
    "        # prepare for the prediction\n",
    "        pred = []\n",
    "        for i in test_idx:\n",
    "            l = np.where(A[i] !=0)[0]  # searching neigbhours for a masked node\n",
    "            if(len(l)!= 0):\n",
    "                tmp = 0 # filtered_x_lp[i] => add initial node value ? or without mean\n",
    "                for j in l:\n",
    "                    # sum over values from neighbour nodes\n",
    "                    tmp += filtered_x_lp[j]\n",
    "                # compute mean according to total number of neighbours\n",
    "                pred.append(tmp/len(l))   \n",
    "            else:\n",
    "                # if the node has no neighbour then the value will be its signal values\n",
    "                pred.append(filtered_x_lp[i])\n",
    "\n",
    "        # thresholding over the prediction so that only 1 or -1 will be returned\n",
    "        pred_thres = np.array(pred)\n",
    "        pred_thres [pred_thres >0 ] = 1\n",
    "        pred_thres [pred_thres <0 ] = -1\n",
    "\n",
    "        # compute the f1 score of the prediction and add to scores list\n",
    "        f1_scores.append(sm.f1_score(truth,pred_thres))\n",
    "        \n",
    "    # compute mean of all obtained scores\n",
    "    mean = np.mean(f1_scores)\n",
    "    # compute variance of all obtained scores\n",
    "    var = np.std(f1_scores)\n",
    "    print(\"The mean is \",mean)\n",
    "    print(\"The variance is \",var)\n",
    "    return mean,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       0.302760\n",
       "31       0.316083\n",
       "81       0.310380\n",
       "98       0.300111\n",
       "115      0.293537\n",
       "           ...   \n",
       "86255    0.302733\n",
       "86278    0.329863\n",
       "86294    0.289025\n",
       "86310    0.309895\n",
       "86322    0.317928\n",
       "Name: Unemployment rate, Length: 3141, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_unemployment_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29      1\n",
       "30      1\n",
       "31      1\n",
       "32      1\n",
       "33      1\n",
       "       ..\n",
       "3136    1\n",
       "3137   -1\n",
       "3138    1\n",
       "3139    1\n",
       "3140    1\n",
       "Name: Winner, Length: 3141, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_presidential_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xzou/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-25eda47c1036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_mean_migration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_var_migration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_migration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_unemployment_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lp_migration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-e51fe36f494e>\u001b[0m in \u001b[0;36mpred_iteration\u001b[0;34m(A, iters, y, n, filtered_x_lp)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# compute the f1 score of the prediction and add to scores list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mf1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# compute mean of all obtained scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ntds_2019/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "accuracy_mean_migration, accuracy_var_migration = pred_iteration(A_migration,iters, y_unemployment_rate, n, x_lp_migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mean_migration, accuracy_var_migration = pred_iteration(A_migration,iters, y_presidential_result, n, x_lp_migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_unemployment_rate,var_unemployment_rate = apply_gcn(iters,X_us,unemployment_rate,A_migration,laplacian_migration,lamb_migration,U_migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_presidential_result,var_presidential_result = apply_gcn(iters,X_us,y_presidential_result,A_migration,laplacian_migration,lamb_migration,U_migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
